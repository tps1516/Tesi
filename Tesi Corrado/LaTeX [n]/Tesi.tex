\documentclass[12pt,a4paper,twoside,openright]{book}
\usepackage[Italian]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage{fancyhdr}
\newcommand{\fncyblank}{\fancyhf{}}
\newenvironment{abstract}%
{\cleardoublepage\fncyblank\null \vfill\begin{center}%
\bfseries \abstractname \end{center}}%
{\vfill\null}

\begin{document}

\begin{abstract}
Questo lavoro di tesi punta a migliorare le previsioni dei valori di dati multi-variati migliorando l'accuratezza senza trascurarne l'efficienza. 
\end{abstract}
\tableofcontents

\chapter{Introduzione}
La rapida evoluzione, vissuta negli ultimi decenni, per la scienza e la tecnica ci porta oggi  a collezionare moli di dati impressionanti. È proprio in questi casi che soluzioni di analisi innovative che combinino informatica e statistica si rendono necessarie. 

In questi termini si presenta la problematica di dover effettuare previsioni accurate di ciò che sarà l’andamento futuro di un flusso di dati multi-variati e continuo nel tempo.

Al fine di risolvere tale problematica si utilizzano tecniche di data mining capaci di gestire tali flussi e di fornirne una rappresentazione funzionale all’applicazione di modelli di regressione che sono utili ad effettuare previsioni sull’andamento futuro dei dati in osservazione. 

In questo lavoro di tesi, partendo da un algoritmo che effettua previsione dopo aver applicato una tecnica di clustering incrementale e aver appreso un modello di regressione chiamato “Vector Autoregressive Model”, si investiga l’utilizzo della tecnica dello smoothing esponenziale e la costruzione di aggregati dei dati osservati in tempo reale, al fine di ottenere un bilanciamento tra accuratezza e efficienza nella costruzione di un modello di previsione multi-variato in reti di sensori.



In questo capitolo vengono descritti lo scenario applicativo all’interno del quale questo lavoro di tesi si colloca e si riporta una sintetica descrizione degli obiettivi prefissati. 
\newpage
\section{Scenario applicativo}
L’ormai diffuso uso delle reti di sensori ha portato a dover gestire sistemi informatizzati in grado di misurare e organizzare dati multi-variati in tempo reale. Tali sistemi si avvalgono dei cosiddetti geosensori, ovvero di dispositivi in grado di eseguire rilevazioni temporali multiple di fenomeni fisici quali per esempio temperatura, umidità, velocità del vento e livello delle radiazioni solari. 


Il fine ultimo di tali rilevazioni è senza dubbio quello di dover effettuare previsioni accurate di ciò che potrà essere l’andamento futuro di tali fenomeni, ma utilizzare queste informazioni non è semplice, non perché sia complicato leggerle, ma piuttosto perché è difficile interpretarle. 


È in questo contesto che l’algoritmo VARForecaster trova spazio, infatti utilizza una tecnica che ci aiuta a raffinare le informazioni derivanti dai geosensori proveniente dall’insieme di tecniche e metodologie definito data mining e che si chiama analisi dei cluster. L’utilizzazione di questa tecnica ci permette di raggruppare i geosensori in base alla loro vicinanza spaziale e alla similarità delle loro osservazioni.

Per ognuno di questi gruppi distinti, si possono costruire modelli di regressione, ovvero è possibile definire un modello secondo il quale “una variabile dipendente è modellata come una funzione delle variabili indipendenti più un termine d'errore” \cite{2a}.

A causa della natura delle rilevazioni, per avere delle previsioni valide e accurate è necessario che esse siano ripetute nel tempo, portando infine ad avere una serie temporale multi-variata (che considera più di un fenomeno) e georeferenziata (cioè geograficamente distribuita).


La previsione in un serie temporale multi-variata è realizzata con l'apprendimento di un modello VAR che restituisce un modello di regressione per ciascuna variabile. Tale modello di regressione predice i valori attesi per la variabile dipendente in funzione delle osservazioni storiche collezionate tanto per la variabile dipendente, cioè da predire, quanto per le variabili indipendenti, ovvero quelle rimanenti nel sistema di variabili misurate \cite{3a}. L'apprendimento di un modello VAR per sensore è computazionalmente costoso. La alternativa è l'apprendimento di un modello VAR per gruppi cluster di sensori.


In \cite{donato} si presenta un algoritmo, VARForecaster che combina modello di clustering e modello VAR. Il clustering è realizzato in maniera incrementale sulla base di approssimazioni dei valori osservati, ovvero si forma incrementalmente una gerarchia di cluster, partendo da un nodo radice inizialmente vuoto e aggiungendo istanze una alla volta aggiornando l’albero appropriatamente ad ogni passaggio, anche se questo comporta la ristrutturazione dell’albero \cite{4a}.

In questo lavoro di tesi si presenta una variante di tale algoritmo che: (1) valuta l'uso del meccanismo di smoothing esponenziale per determinare il modello di clustering sulla base dei valori geofisici attesi nella rete all'istante t+1 piuttosto che sulla base dei valori geofisici osservati all'istante t; (2) calcola aggregati dei dati in tempo reale (media o mediana) piuttosto che ricorrere ad approssimazioni degli stessi. Lo scopo è identificare la soluzione che realizza il miglior bilanciamento tra accuratezza e efficienza.
\newpage
\section{Obiettivi e contributi}
Questo lavoro di tesi considera un algoritmo incrementale di clustering spazio-temporale multi-variato e lo estende nelle seguenti direzioni: 
\begin{itemize}
\item definizione, nell’albero binario rappresentante il clustering, di un nuovo criterio di ricalcolo della media dei nodi creati ex-novo in fase di riapprendimento (in \cite{donato} si era definito un calcolo basato sulla media del padre per ognuno di essi);
\item utilizzo, per il riapprendimento dell’albero suddetto, dell’algoritmo di smoothing esponenziale, al fine di fornire un mezzo più efficace per la previsione dei valori futuri della serie di dati (in \cite{donato} tale albero era appreso solo in base ai valori ricevuti dai sensori, presenti all’interno della finestra temporale di ogni nodo).
\end{itemize}
\chapter{Stato dell'arte}
\section{Smoothing}
Come definito in precedenza, a causa della natura delle rilevazioni, al fine di migliorare l'accuratezza delle previsioni è indispensabile che queste siano ripetute nel tempo, e che quindi sia fornita una serie temporale di esse.

In questo lavoro di tesi si considera il caso in cui la serie temporale è multi-variata, ovvero prende in considerazione più variabili, e geo-referenziata, cioè i valori sono rilevati da sensori geograficamente distribuiti.

Una serie temporale, quindi, altro non è che una sequenza di osservazioni le quali sono state ripetute nel tempo. 

In una serie temporale, così come in una qualsiasi collezione di dati temporalmente distribuita, i valori assunti dalle variabili hanno una certa variazione random. 

Esistono delle tecniche per ridurre gli effetti dovuti a tali variazioni, e che se utilizzate appropriatamente, rivelano con più chiarezza i pattern nascosti presenti tra i dati. Queste sono dette tecniche di "smoothing" \cite{5a}. 

Lo smoothing è un processo che viene usato per la previsione di valori futuri in una serie temporale e, in statistica e nel campo dell'elaborazione digitale delle immagini, per evidenziare i pattern significativi presenti all'interno dei dati, attenuando il rumore generato da artefatti ambientali, informatici o elettronici. 

Nella pratica esso è un processo in cui i valori presenti in un dataset sono mediati con i loro vicini spaziali o temporali in una serie, tipo una serie temporale, o un'immagine \cite{6a}. 

Ci sono diversi tipi di smoothing:
\begin{itemize}
\item Media mobile semplice: per la previsione vengono considerate tutte le osservazioni precedenti, alle quali viene dato lo stesso peso, indipendentemente dall'istante temporale in cui ci troviamo. La relativa formula per il calcolo è la seguente

\begin{center}
$Y_{t+1}$ = $Y_{t}$+$Y_{t-1}$+$Y_{t-2}$+ ... + $Y_{t-n+1}$ n
\end{center}

\item Media mobile ponderata: è una variante dello smoothing a virgola mobile ed in questo caso i valori precedenti non hanno tutti lo stesso peso, bensì viene assegnato ad ognuno di essi un fattore, chiamato peso, che varierà l'influenza di tale termine all'interno della sommatoria. La formula è così definita

\begin{center}
$Y_{t+1}$ = $p_{1}$ $Y_{t}$+ $p_{2}$ $Y_{t-1}$+ $p_{3}$ $Y_{t-2}$+ ... + $p_{n}$ $Y_{t-n+1}$
\end{center}

dove 
$p_{{i}}$ > {0} e $\sum_{i=1}^{i={n}}{ p_{{i}}} = {1}$


\item Esponenziale.
\end{itemize}

Nella seguente sezione è descritto lo smoothing esponenziale nel dettaglio.
\newpage
\subsection{Exponential Smoothing}
Lo smoothing esponenziale nacque alla fine degli anni '50 (i pionieri furono Holt nel 1957, Brown nel 1959 e Winters nel 1960) e motivò alcuni dei metodi di previsione (forecast) di maggior successo. Le previsioni ottenute con i metodi di smoothing esponenziale sono medie ponderate delle osservazioni passate, con i pesi che diminuiscono in modo esponenziale con l'andare avanti delle osservazioni. 

In altri termini, le osservazioni più recenti hanno un peso associato più alto. 

Questo modo di operare genera previsioni accurate in modo più veloce e per un ampio spettro di serie temporali, il che è un grande vantaggio per le applicazioni in campo industriale \cite{7a}.

Essendo l'idea di base quella di "pesare" maggiormente le osservazioni più recenti rispetto a quelle più remote nel passato, i metodi di smoothing sono capaci di adeguarsi rapidamente a variazioni improvvise nel valore della serie storica a causa di eventi che modificano la regolarità del fenomeno osservato, come per es. può essere un giorno con elevata umidità oppure particolarmente ventoso. 

Esistono diversi metodi di smoothing esponenziale, che tengono conto o meno dell'esistenza di componenti tendenziali e stagionali nella serie storica in esame e sono:
\begin{itemize}
\item Metodo di Brown;
\item Metodo di Holt;
\item Metodo di Winters.
\end{itemize}

\subsubsection{Metodo di Brown}
Il {\bfseries metodo di Brown} è il più semplice e la sua formula è la seguente:
\begin{center}
$Y_{t}$ = $\alpha$ $x_{t}$ + (${1 - \alpha }$) $Y_{t-1}$
\end{center}

dove $\alpha$ è il fattore di smoothing, con 0 $\leq$ $\alpha$  $\leq$ 1. In altre parole $Y_{t}$ è la media pesata dell'osservazione corrente $x_{t}$ ed il precedente termine a cui era stato applicato lo smoothing $Y_{t-1}$. Il fattore di smoothing è il termine, all'interno dell'equazione, che indica quanto peso dare al fattore precedente o all'osservazione corrente. 

Infatti se $\alpha$ = 1 la serie in uscita allo smoothing è sempre quella ricevuta in ingresso, mentre man mano che si abbassa il valore di questo fattore si ha minor adattamento ai dati correnti fino a quando, con $\alpha$ = 0, si avrà in output sempre la serie di partenza.

In questo metodo il valore $Y_{1}$ è uguale al valore della prima osservazione effettuata $x_{1}$.

Questo tipo di smoothing esponenziale è molto facile da applicare, infatti basta che due osservazioni siano disponibili per poterlo utilizzare e non tiene conto ne di eventuali trend né di stagionalità all'interno della serie temporale.
\subsubsection{Metodo di Holt}
Il {\bfseries metodo di Holt} migliora il modello di Brown, infatti tiene conto dei trend presenti all'interno della serie temporale (ma non della stagionalità). La formula per calcolare la previsione con il suddetto metodo è la seguente:

 \begin{center} 
$Y_{t+1}$ = $Y_{t}$ + $m_{t}$  
\end{center} 
\begin{flushright}
(1)
\end{flushright}

dove: 
\begin{itemize}

\item $Y_{t}$ = $\alpha$ $x_{t}$ + (${1 - \alpha }$)($Y_{t-1}$ + $m_{t-1}$) $\forall$ $t$ $\geq$ 2 
\begin{flushright}
(2)
\end{flushright}
\item $m_{t}$ = $\beta$ ($Y_{t}$ - $Y_{t-1}$)+(1 - $\beta$) $m_{t-1}$ $\forall$ $t$ $\geq$ 2 
\begin{flushright}
(3)
\end{flushright}
\item $Y_{1}$ = $x_{1}$

\item $m_{1}$ = $x_{2}$ - $x_{1}$
\end{itemize}


L'equazione (1) è definita equazione di predizione, la (2) equazione di livello e la (3) come equazione di trend. 

$Y_{t}$ denota lo stimatore della serie temporale all'istante $t$, $m_{t}$ è uno stimatore del trend della serie all'istante $t$, $\alpha$ è, come nel modello di Brown, il parametro di smoothing per la serie e può essere 0 $\leq$ $\alpha$ $\leq$ 1 e $\beta$ invece è il parametro di smoothing per il trend e può anch'esso assumere valori 0 $\leq$ $\beta$ $\leq$ 1. 
$\beta$ deve essere ottimizzato minimizzando lo scarto quadratico medio.

\subsubsection{Metodo di Winters}

Il {\bfseries metodo di Winters}, infine, è il metodo di smoothing esponenziale con più alta complessità ma che si preoccupa di tenere in considerazione, oltre che dei trend presenti all'interno della serie temporale, anche di una stagionalità di periodo L nota. Esso si calcola come segue:

\begin{center}
$Y_{t+1}$ = ($Y_{t}$ + $m_{t}$) $q_{t-L+1}$
\end{center}
\begin{flushright}
(1)
\end{flushright}
dove:
\medskip \medskip
\begin{itemize}

\item $Y_{t}$ = $\alpha$ $\frac{Y_{t}}{q_{t-L} }$ + (1 - $\alpha$)($Y_{t-1}$ + $m_{t-1}$) $\forall$ $t$ $\geq$ 2 
\begin{flushright}
(2)
\end{flushright}
\item $m_{t}$ = $\beta$ ($Y_{t}$ - $Y_{t-1}$) + (1- $\beta$)$m_{t-1}$   $\forall$ $t$ $\geq$ 2
\begin{flushright}
(3)
\end{flushright}
\item $q_{t}$ = $\gamma$ $\frac{x_{t}}{Y_{t}}$ + (1 - $\gamma$) $q_{t-L}$  $\forall$ $t$ $\geq$ L + 1 
\begin{flushright}
(4)
\end{flushright}
\item $q_{t}$ = $\frac{x_{t}}{\sum_{\tau=1}^{L}{\frac{x_{\tau}}{L}}}$ $\forall$ $t$ = 1, $\dots$ , L
\begin{flushright}
(5)
\end{flushright}

\item $Y_{1}$ = $x_{1}$

\item $m_{1}$ = $x_{2}$ - $x_{1}$
\end{itemize}

L'equazione (1) è definita equazione di predizione, la (2) equazione di livello, la (3) equazione di trend, mentre la (4) e la (5) sono chiamate equazioni di periodo.

$Y_{t}$ denota lo stimatore della serie temporale all'istante $t$, $m_{t}$ è uno stimatore del trend della serie all'istante $t$ e $q_{t}$ indica uno stimatore della periodicità della serie all'istante $t$, il quale deve essere calcolato in due modi diversi che dipendono dall'istante temporale in cui ci si trova rispetto all'intera durata del periodo.

$\alpha$ è il parametro di smoothing per la serie e può essere 0 $\leq$ $\alpha$ $\leq$ 1, allo stesso modo $\beta$, che è il parametro di smoothing del trend della serie temporale, deve essere 0 $\leq$ $\beta$ $\leq$ 1, invece $\gamma$ è il parametro di smoothing del periodo e può essere 0 $\leq$ $\gamma$ $\leq$ 1. 

$\gamma$ deve essere ottimizzato minimizzando lo scarto quadratico medio.

\medskip \medskip

È possibile, nel caso lo si desideri, eliminare da una serie temporale la componente di tendenza o di stagionalità.
Innanzitutto bisogna determinare la tendenza con un'analisi di regressione e la componente di stagionalità tramite scomposizione della serie, successivamente è possibile calcolare la media mobile per rimuovere la tendenza e, per differenziazioni successive ($B_{t}$($h$) = $y_{t}$ - $y_{t-h}$), è possibile rimuovere la tendenza \cite{8a}.

\newpage
\section{Vector Autoregressive Model}
Il modello VAR (Vector Autoregressive Model) è uno dei modelli  più flessibili, facili da usare e di successo per l'analisi di serie temporali multivariate. E' un'estensione naturale del modello autoregressivo univariato verso il dinamismo delle serie temporali multivariate. Il modello VAR ha dimostrato di essere molto utile per descrivere il comportamento dinamico delle serie storiche economiche e finanziarie e per le previsioni. Esso fornisce previsioni spesso più accurate rispetto a quelle dei modelli univariati, infatti queste possono essere condizionate da potenziali percorsi futuri che le variabili nel modello possono prendere. Oltre alla descrizione dei dati e la previsione, il modello VAR può essere usato per l'inferenza struttura e per l'analisi della linea di condotta \cite{13a}. 

L'analisi del modello VAR può essere affrontata da due punti di vista: 
\begin{itemize}
\item dal punto di vista teorico: è in questa sezione descritta la storia di tale modello e la teoricità sulla quale è basato;
\item dal punto di vista implementativo: è invece qui descritta la tecnica di utilizzazione del modello VAR in base alle necessità di questo progetto di tesi.
\end{itemize}
\newpage 
\subsection{Modelli teorici}
I modelli VAR sono stati definiti da Christopher Sims in uno storico articolo pubblicato su Econometria nel 1980, che proponeva una critica dei modelli strutturali di equazioni simultanee, allora il principale strumento di analisi ecometrica nell'ambito della macroeconomia. 

In particolare, i modelli VAR risultano nel complesso più semplici rispetto ai modelli strutturali, e la loro performance in termini di capacità previsiva di variabili macroeconomiche appare migliore.

Tutte le n variabili date in input al modello, vengono trattate simmetricamente in senso strutturale dove ognuna di essa sarà ricavata da un’equazione che spiega la sua evoluzione in base ai ritardi di se stessa e ai ritardi di tutte le altre variabili. 

Le variabili che vengono date in input al modello VAR, prendono il nome di variabili endogene e vengono raccolte in un vettore $Y_{t}$ di dimensione n x 1 che ha come i-esimo elemento $Y_{it}$ e dove quest’ultimo rappresenta l’osservazione della variabile i-esima al tempo t. Ad esempio se la variabile i-esima è la velocità del vento, allora $Y_{it}$ è il valore della velocità del vento al tempo t \cite{9a} \cite {10a}. 

Un modello VAR, in generale, è un sistema di equazioni simultanee che può essere descritto mediante tre modelli teorici: reduced form (o forma ridotta), structural form (o forma strutturale) e companion form.  
\subsubsection{Reduced form}
Il modello VAR in forma ridotta si presenta nella forma:
\begin{center}
{\bfseries  $Y_{t}$ = c + $\Phi$(L)$Y_{t-1}$ + $\varepsilon_{t}$ = c + $\Phi_{1}$ $T_{t-1}$ + $\dots$ + $\Phi_{p}$ $Y_{t-p}$ + $\varepsilon_{t}$ }
\end{center}

dove, per un  VAR(p) {\bfseries  $\Phi$(L) = $\sum_{i=0}^{p-1}{\Phi_{i} L^{i}}$} è un polinomio matriciale di ordine p nell'operatore di ritardo {\bfseries L} (ossia, l'operatore tale che {\bfseries $L^{i}$ $Y_{t}$ = $Y_{t-1}$}), con {\bfseries $\Phi_{i}$} che è una matrice di dimensione n x n; 

{\bfseries $Y_{t}$} è il vettore delle variabili endogene e si presenta nella forma:
\begin{center}
{\bfseries $Y_{t}$ = $\begin{bmatrix}
Y_{1t}\\ \vdots \\ Y_{nt} 
\end{bmatrix}$ }
\end{center}
e $\varepsilon_{t}$ è un vettore conforme di disturbi stocastici del tipo:
\begin{center}
{\bfseries $\varepsilon_{t}$ = $\begin{bmatrix}
\varepsilon_{1t}\\ \vdots \\ \varepsilon_{nt} 
\end{bmatrix}$ }
\end{center}
tali che {\bfseries $E_{\varepsilon_{t}}$ = 0} (ogni termine di disturbo ha media pari a zero) e {\bfseries E($\varepsilon^2_{it}$) = $\sigma^2_{i}$} con {\bfseries i = 1, \dots, n} dove {\bfseries $\sigma^2_{i}$} è la varianza i-esima ed E la media. Si osservi che gli elementi del vettore $\varepsilon_{t}$ non sono necessariamente non correlati, cioè che in generale {\bfseries E($\varepsilon_{it}$ $\varepsilon_{jt}$) = $\sigma_{ij}$ $\neq$ 0 } (la deviazione standard fra due elementi di $\varepsilon_{t}$ può essere diversa da zero) per elementi di $\varepsilon$ indicizzati da {\bfseries i, j}  con {\bfseries j $\neq$ i}; per contro, per ipotesi nessuna delle componenti del vettore $\varepsilon$ esibisce correlazione seriale, ossia {\bfseries E($\varepsilon_{it}$ $\varepsilon_{i \tau}$) = 0, $\forall{i}$ e $\forall{\tau}$ $\neq$ t}.

Infine, resta da indicare il vettore {\bfseries c}, ossia il vettore delle costanti (o intercetta) che si presenta nella seguente forma: 
\begin{center}
{\bfseries c = 
$\begin{bmatrix}
c_{1} \\ \vdots \\ c_{n}
\end{bmatrix}$  }
\end{center}

Per capire ancora meglio la reduced form, consideriamo il modello VAR dal punto di vista della stima dei coefficienti, in modo tale da poterlo scrivere anche nel seguente modo: 
\begin{center}
{\bfseries
$y_{1t}$ = $c_{1}$ + $\varphi^{(1)}_{11}$ $y_{1t-1}$ + $\dots$ + $\varphi^{(p)}_{1p}$ $y_{nt-p}$ + $\varepsilon_{1t}$ 

$\vdots$

$y_{nt}$ = $c_n$+ $\varphi_{n1}^{(1)}y_{1t-1}$+$\dots$+$\varphi_{np}^{(p)}y_{nt-p}$+$\varepsilon_{nt}$
}
\end{center}

Osservando che al secondo membro di ogni equazione figurano le stesse variabili, il VAR(p) risulta equivalente ad un modello SURE (Seemingly Unrelated Regression Equations), i cui coefficienti possono essere stimati considerando ogni equazione come una regressione lineare standard, indipendente dalle altre. In particolare, gli stimatori OLS (Ordinary Least Squares) ottenuti con il metodo dei minimi quadrati, risultano consistenti e cioè che all'aumentare dell'informazione, la distribuzione di probabilità di ognuna di esso, si concentra in corrispondenza del valore del parametro da stimare \cite{11a}.
\subsubsection{Structural form}
La structural form di un modello VAR(p) è formalizzata da un'equazione del tipo:
\begin{center}
{\bfseries 
$A_o$ $Y_t$ = m + $A$ (L) $Y_{t-1}$ + $u_t$
}
\end{center}
dove {\bfseries m} è simile al vettore di costanti {\bfseries c} della reduced form, {\bfseries $A_0$} è la matrice n x n che identifica le relazioni strutturali contemporanee tra le diverse componenti di {\bfseries $Y_t$}, mentre il vettore {\bfseries $u_t$} è chiamato rumore bianco ed è un vettore di disturbi che in particolare ha componenti tra loro correlate: {\bfseries E($u_{it}$ $u_{ij}$) = 0} per {\bfseries j $\neq$ i}.

Come si può notare, la forma strutturale è molto simile a quella ridotta con la differenza di avere la matrice $A_0$ al primo membro: all'interno di essa, e precisamente, sulla sua diagonale principale, si avranno elementi tutti pari a 1 e quindi vuol dire che il valore 1 lo si avrà alla variabile i-esima in corrispondenza dell'equazione i-esima. 

La structural form è una forma di supporto per la reduced form, e questo perché possiamo passare dalla prima forma alla seconda pre-moltiplicando a sinistra di ambo i membri l'inversa della matrice $A_0$:
\begin{center}
{\bfseries
$\mathbf{Y}_t$=$A_0^{-1}$ $\mathbf{m}$+$A_0^{-1}$ $A(L)$ $\mathbf{Y}_{t-1}$+$A_0^{-1}u_t$=$\mathbf{c}$+$\Phi(L)$ $\mathbf{Y}_{t-1}$+$\varepsilon$
}
\end{center}

Quest'ultima la si può riscrivere in questo modo:
\begin{center}
{\bfseries
$\left(I-\Phi(L)L\right)$ $\mathbf{Y}_t$=$\mathbf{c}$+$A_0^{-1}$ $u_t$
}
\end{center}

da cui si ottiene una forma detta forma finale del modello VAR(p) o rappresentazione di Wold:
\begin{center}
{\bfseries
$\mathbf{Y}_t$=$\left(I-\Phi(L)L\right)^{-1}\mathbf{c}+\left(I-\Phi(L)L\right)^{-1}$ $A_0^{-1}$ $u_t$=$\mathbf{\mu}$+$\Psi$(L)$u_t$
}
\end{center}

dove {\bfseries I} è la matrice identica, {\bfseries $\Psi$ (L)} è un polinomio matriciale nell'operatore L di ordine finito, e {\bfseries $\mu$} è il valore atteso non condizionato di {\bfseries $Y_t$}. In altre parole, il VAR(p), processo vettoriale autoregressivo di ordine finito, è equivalente a un processo in media mobile di ordine infinito.
\subsubsection{Companion form}
La companion form di un modello VAR(p) è la riscrittura della sua reduced form con l'accorpamento di p espressioni vettoriali. L'equazione rappresentante questa nuova forma è la seguente:
\begin{center}
{\bfseries
$\begin{bmatrix}\mathbf{Y}_t\\\mathbf{Y}_{t-1}\\\vdots\\\mathbf{Y}_{t-p+1}\\\end{bmatrix}$=$\begin{bmatrix}\mathbf{c}\\\mathbf{0}\\\vdots\\\mathbf{0}\end{bmatrix}$+$\begin{bmatrix}\Phi_1 & \Phi_2 & \cdots & \Phi_{p-1} & \Phi_p\\ I & \mathbf{0} & \cdots & \mathbf{0} & \mathbf{0}\\ \mathbf{0} & I & \cdots & \mathbf{0} & \mathbf{0}\\ \vdots & \vdots & \ddots & \vdots & \vdots\\ \mathbf{0} & \mathbf{0} & \cdots & I & \mathbf{0}\end{bmatrix}$ $\begin{bmatrix}\mathbf{Y}_{t-1}\\\mathbf{Y}_{t-2}\\\vdots\\\mathbf{Y}_{t-p}\\\end{bmatrix}$ + $\begin{bmatrix}A_0^{-1}u_t\\ \mathbf{0}\\ \vdots\\ \mathbf{0}\end{bmatrix}$
}
\end{center}

Seguendo la notazione prima descritta, si possono identificare, in questa equazione, quattro vettori di vettori e una matrice di matrici, dove gli zeri presenti nei vettori e nella matrice rappresentano rispettivamente vettori nulli di dimensione n x 1 e matrici nulle di dimensioni n x n. 

È possibile riscrivere l'equazione nel seguente modo: 
\begin{center}
{\bfseries
$Z_t$ = $\lambda$ + $F$|$Z_{t-1}$ + $\xi_t$
}
\end{center}
dove E($\xi_t$) = 0, ed essendo $\xi_t$ = [$\xi^{'}_1$, $\dots$, $\xi^{'}_T$]', si ha E($\xi$ $\xi^{'}$) = $\sum$ $\otimes$ $I_t$ dove $\sum$ è la matrice varianze-covarianze dei disturbi $\varepsilon$ e $\otimes$ indica il prodotto di Kroenecker.
\medskip

È importante sottolineare, infine, che la forma adottata generalmente da un modello VAR per effettuare analisi statistiche dei dati, è la {\bfseries reduced form}.
\newpage
\subsection{Implementazione in R}
R è un linguaggio e un ambiente di sviluppo per l'analisi statistica e grafica.

È un progetto GNU simile al linguaggio e ambiente di sviluppo S, il quale fu sviluppato ai laboratori Bell (Bell Laboratories) da John Chambers e i suoi colleghi. R può essere considerato come una diversa implementazione di S. Ci sono importanti differenze, ma molto del codice scritto in S può essere eseguito senza dover apporre modifiche in R. 

R fornisce un'ampia varietà di tecniche statistiche (modellazione lineare e non, test statistici classici, analisi di serie temporali, classificazione, clustering, $\dots$) e grafiche ed è molto estendibile. 

Le sue caratteristiche principali sono:
\begin{itemize}
\item semplicità nella gestione e manipolazione dei dati;
\item disponibilità di una suite di strumenti per calcoli su vettori, matrici, ed altre operazioni complesse;
\item accesso ad un vasto insieme integrati per l'analisi statistica;
\item produzione di numerose potenzialità grafiche particolarmente flessibili;
\item possibilità di adoperare un vero e proprio linguaggio di programmazione orientato ad oggetti che consente l'uso di strutture condizionali e cicliche, nonché di funzioni create dall'utente;
\end{itemize}
È distribuito gratuitamente sotto i vincoli GPL (General Public License) ed è disponibile per diverse architetture hardware e sistemi operativi: Unix, Linux, Windows, MacOS. Sul sito della  CRAN (\url{<http:\\www.r-project.org)>} è possibile scaricare, oltre che il programma base, anche una serie di moduli aggiuntivi e un'ampia manualistica sull'ambiente, che va dall'installazione del software al suo utilizzo all'analisi dei dati \cite{12a}.

Sono di seguito descritte le due funzioni in R considerate nella realizzazione di questo progetto di tesi:
\begin{itemize}
\item VARselect;
\item VAR;
\end{itemize}
\newpage
\subsubsection{VARSelect}
\begin{center}
{\bfseries 
VARselect(y, lag.max = value1, type = value2, season = value3, exogen = value4)
}
\end{center}
dove:
\begin{itemize}
\item y è la matrice delle variabili endogene (cap. 2.1);
\item lag.max, ossia il valore value1, è il massimo ordine di ritardo che si potrà avere nel modello VAR;
\item type, nonché value2, rappresenta il tipo di regressori deterministici da includere nel modello VAR e uno dei possibili valori che può essere assegnato è: "const" (costante), "trend" (tendenza), "both" (entrambi, cioè costante e tendenza) e "none" (nessuno);
\item season è la frequenza stagionale (periodicità) dei dati. Se value3 = 4 vorrebbe dire che si avranno dei dati trimestrali. Può assumere valore "NULL" e in questo caso indicherebbe un'assenza di stagionalità;
\item exogen, ovvero value 4, rappresenta la matrice delle variabili esogene, cioè delle variabili indipendenti. Può assumere valore "NULL" e sta ad indicare che non ci sono variabili esogene.
\end{itemize}

Gli output sono:
\begin{itemize}
\item selection. È il vettore degli ordini ottimali ottenuti ognuno da ogni criterio possibile. I criteri sono delle funzioni avente un solo input e i criteri possibili sono quattro;
\item criteria. È la matrice di dimensione 4 x lag.max contenente i valori ottenuti da ogni criterio attribuendo input che vanno da 1 fino a lag.max.
\end{itemize}
\subsubsection{VAR}
\begin{center}
{\bfseries 
VAR(y, p = value1, type = value2, season = value3, exogen = value4, lag.max = value5, ic = value6)
}
\end{center}
dove i parametri già specificati per la funzione VARselect valgono anche qui mentre:
\begin{itemize}
\item p, nonché value1, rappresenta l'ordine di ritardo scelto per il modello VAR;
\item ic, cioè value6, è l'informazione sul criterio utilizzato. I possibili criteri sono: "AIC" (Akaike), "HQ" (Hannan-Quinn), "SC" (Schwarz), "FPE" (Forecast Predict Error).
\end{itemize}
Gli output invece sono:
\begin{itemize}
\item p. È l'ordine di ritardo dato in input;
\item K. Rappresenta la dimensione del modello VAR (cioè è il numero di attributi della matrice y data in input alla funzione VAR);
\item varresult. È la lista di oggetti di regressione, dove ogni oggetto sarà associato al rispettivo attributo della matrice y data in input alla funzione VAR. Ad ognuno di questi oggetti è associato un vettore di coefficienti stimati tramite la regressione che si chiama coefficients. Questo vettore avrà un numero di coefficienti pari a p x K \cite{13a}.
\end{itemize}
\newpage
\section{Clustering}

\newpage
\subsection{Clustering Interpolativo}
\newpage
\section{VARForecaster 1.0/2.0}
\chapter{VARForecaster 2.1/2.2}
In questo capitolo sono descritte le versioni dell'algoritmo (descritto nel par. 2.4) progettate ed implementate in questo lavoro di tesi. 

È importante ricordare che (come descritto nel par. 1.1) all'algoritmo VARForecaster sono apportate modifiche che permettono di calcolare gli aggregati dei dati in tempo reale (media o mediana) piuttosto che ricorrere ad approssimazione degli stessi e utilizzare un meccanismo di smoothing esponenziale per determinare il modello di clustering sulla base dei valori geofisici attesi nella rete all'istante {\bfseries t+1} piuttosto che sulla base dei valori osservati all'istante {\bfseries t}. La motivazione che ha portato a tali obiettivi è l'identificazione di una soluzione che realizza il miglior bilanciamento tra accuratezza e efficienza.
\section{VARForecaster 2.1}
In questa versione dell'algoritmo 
Come descritto nel capitolo 2.4, la costruzione dell'albero avviene in maniera incrementale, ovvero, ad ogni nuovo snapshot di dati all'interno dello stream, l'algoritmo controlla che le condizioni di split secondo il quale allo snapshot t-1 è stato applicato il cluster, siano ragionevoli anche per lo snapshot ricevuto all'istante t.

Questo metodo viene messo in atto attraverso un processo prima di pruning e poi di ri-apprendimento dell'albero sulla base dei nuovi valori ricevuti. 

Il pruning è un processo ricorsivo nel quale vengono analizzati i nodi di split, i quali sono potati se la loro condizione di split non porta ad una reale riduzione della varianza degli indicatori locali di autocorrelazione spaziale sui nuovi record. 

Nel caso in cui venga applicata la potatura, il nodo di split viene sostituito con un nodo foglia, al cui interno ricadranno tutte le istanze precedentemente appartenenti al nodo di split. 

La fase di ri-apprendimento dell'albero, al contrario di quella di pruning, prende in considerazione i nodi foglia, è infatti in questa fase che l'algoritmo VARForecaster tenta di apprendere nuovi sotto-alberi.

Secondo la versione 2.0 dell'algoritmo, nel momento in cui viene appreso un nuovo nodo, a questo viene assegnata, nella struttura dati che tiene traccia delle medie multi-variate assunte da ogni cluster (cioè la struttura dati \textit{Feature Window}), la media precedente calcolata per il suo nodo padre (vedi par. 2.4). 

\subsubsection{Real Time Aggregate}
È in questa fase del processo che si è deciso di apportare una modifica all'algoritmo VARForecaster 2.0. 

Infatti, volendo trovare una maniera per aumentare l'accuratezza senza inficiare eccessivamente sull'efficienza, si è pensato di ricostruire, per ogni nuovo nodo appreso, la media multi-variata ad esso associata, in modo tale da mantenere un'aggregato multi-variato calcolato sulla base dei reali valori assunti dalle istanze dei sensori che ricadono all'interno del cluster foglia.

Questo processo è realizzato all'interno della struttura dati \textit{Node} e si sviluppa nei seguenti passi:
\begin{itemize}
\item Per ogni sensore appartenente al cluster foglia:
\begin{itemize}
\item viene letta la serie storica multi-variata ad esso associato;
\item per ogni caratteristica (\textit{Feature}) presente all'interno della serie:
\begin{itemize}
\item per ogni istante temporale precedente a t, viene letto il valore corrispondente e lo si somma agli altri valori letti per la caratteristica in esame;
\item viene incrementato un contatore, il quale sarà necessario per definire quanti istanti temporali sono stati sommati.
\end{itemize}
\end{itemize}
\end{itemize}

Alla fine di tale procedimento, per ogni sensore, sono divisi la somma ottenuta per ogni \textit{Feature} ed il valore del contatore a quella caratteristica associata.

Questi valori rappresentano la media, per ogni \textit{Feature}, delle rilevazioni effettuate fino all'istante t dall'insieme di sensori che ricadono all'interno del cluster foglia.
Tali valori sono poi accodati all'insieme delle rilevazioni precedentemente effettuate dal sensore, per ogni singola \textit{Feature}, nella struttura dati \textit{Feature Window}. 

\subsubsection{Problematiche}
Nel momento in cui si prova a definire un'aggregato multi-variato per un cluster si può incorrere in due inconvenienti:
\begin{itemize}
\item Sensori inattivi;
\item Presenza di outliers;
\end{itemize}
Sono di seguito descritte le modalità secondo le quali è stato possibile risolvere entrambi i problemi.
\subsubsection{Sensori Inattivi}
Nel calcolo della media, come specificato in precedenza, vengono considerate tutte le rilevazioni presenti all'interno della finestra temporale associata al sensore. 

Se tale sensore in passato, anche per un singolo istante temporale \textit{$t_{x}$}, non ha effettuato alcuna rilevazione, nella struttura dati \textit{Feature Window} ad esso associata, per l'istante \textit{$t_{x}$}, è salvato il valore massimo che Java permette per rappresentare una variabile di tipo Double (di seguito definito come \textit{"MAX-VALUE"}).


Se si prendesse in considerazione tale valore nel calcolo della media, quest'ultima risulterebbe definitivamente influenzata. Per evitare ciò, nel momento in cui si calcola la media, si controlla che il valore rilevato non sia \textit{"MAX-VALUE"}.
Nel caso in cui si incorre in tale valore, il sensore incriminato, non viene considerato per il calcolo della media e il contatore non subisce alcuna modifica.
 
\subsubsection{Presenza di outliers}
Data la varietà di dati misurati e la distribuzione geografica dei sensori, è possibile che tra le rilevazioni effettuate possano esserci uno o più ouliers. 

Un outliers è un termine utilizzato in statistica per definire, in un insieme di osservazioni, un valore anomalo e aberrante; un valore quindi chiaramente distante dalle altre osservazioni disponibili \cite{14a} 

Data la struttura di questi dati, che sarebbero assolutamente fuorvianti in caso di aggregati costruiti tramite l'utilizzo della media, è stato messa a disposizione dell'utente, come parametro per il lancio del software, la possibilità di scegliere se calcolare il suddetto aggregato con l'utilizzo della mediana.

In statistica, in particolare in statistica descrittiva, data una distribuzione di un carattere quantitativo oppure qualitativo ordinabile (ovvero le cui modalità possano essere ordinate in base a qualche criterio), si definisce la \textbf{mediana} (o \textbf{valore mediano}) come il valore assunto dalle unità statistiche che si trovano nel mezzo della distribuzione. 

Se si procede al riordinamento delle unità in base ai valori crescenti del carattere da esso detenuto, in sostanza la mediana bipartisce la distribuzione in due sotto-distribuzioni: la prima a sinistra della mediana (costituita dalla metà delle unità la cui modalità è minore o uguale alla mediana) e la seconda a destra della mediana costituita dalla metà delle unità la cui modalità è maggiore o uguale alla mediana). Tecnicamente si afferma che la mediana è il valore per il quale la frequenza relativa cumulata vale (o supera) 0,5. 

Per calcolare la mediana di \textit{n} dati \cite{15a} 
\begin{itemize}
\item si ordinano gli \textit{n} dati in ordine crescente;
\item se il numero di dati è dispari la mediana corrisponde al valore centrale, ovvero al valore che occupa la posizione \textbf{$\frac{n+1}{2}$};
\item se il numero \textit{n} di dati è pari, la mediana è stimata utilizzando i due valori che occupano la posizione \textit{$\frac{n}{2}$} e \textit{($\frac{n}{2}$ + $1$)}
\end{itemize}

A livello implementativo, la differenza fondamentale tra il calcolo degli aggregati multi-variati tramite media rispetto a farlo con la varianza, risiede nell'utilizzo di una struttura dati in cui vengono memorizzati i valori di ogni serie uni-variata per istante temporale \textit{t}.

Da questa struttura si va poi a leggere il valore centrale, ovvero quello corrispondente alla mediana, per poi continuare ad operare come nel caso della media. Nel caso in cui invece il numero \textit{n} di dati sia dispari, si provvede alla lettura dei due valori centrali e all'utilizzo della media per il calcolo del valore mediano.

\subsubsection{Caso limite}
Esiste, in maniera remota, la possibilità che tutti i sensori che ricadono in un cluster foglia, non abbiano mai effettuato alcuna rilevazione, fino all'istante temporale \textit{t} in esame. 

Per la gestione di questa casistica limite si è preferito quindi accodare un valore \textit{"MAX-VALUE"}, come quello presente in caso di sensore inattivo.

Così facendo è in seguito catturata e gestita un'eccezione che non permette il forecast.

\subsubsection{Conseguenze}
A causa della rielaborazione degli aggregati multi-variati in caso di apprendimento di un nuovo nodo, le serie storiche di ciascun cluster foglia risultano essere ora reali, ovvero fittate sulle istanze che realmente ricadono all'interno di tale cluster. Come conseguenza primaria si ha quindi, che la costruzione del modello VAR rispecchierà in maniera maggiore la situazione reale del cluster.
\medskip
\medskip
\medskip
\medskip

Nella prossima sezione seguono i diagrammi di classe e di sequenza della parte di lavoro in questa tesi redatta.
\newpage
\subsection{Progettazione}
In questa sezione sono illustrate, tramite diagrammi delle classi e diagrammi di sequenza, tutte le modifiche apportate all'algoritmo VARForecaster 2.0.
\subsubsection{Diagrammi delle classi}
\newpage
\subsubsection{Diagrammi di sequenza}
\newpage
\section{VARForecaster 2.2}
\newpage
\subsection{Diagrammi di classe}
\newpage
\subsection{Diagrammi di sequenza}

\chapter{Analisi sperimentale}
\newpage
\section{Obiettivi e metriche}
\newpage
\section{Dati}
\newpage
\section{Risultati}
\newpage
\subsection{EcoTexas}
\newpage
\subsection{UnitedStatesPacific}

\chapter{Conclusioni}
\chapter{Appendice}
\section{Guida per l’esecuzione di VARForecaster 2.1/2.2}\
\chapter{Bibliografia}
  \begin{thebibliography}{1}

  \bibitem{donato} D. Mastropasqua. {\em Titolo Tesi Mastropasqua}, 2016: Tesi di laurea in Algoritmi e Strutture Dati, Uniba.

  \bibitem{2a} G. Data, P. Mariani. {\em Market Access nel settore healthcare – Strategie, attori, attività e processi}, 2015:  FrancoAngeli Editori.

  \bibitem{3a} C. Alexander. {\em Market Risk Analysis, Value at Risk Models}, 2009: Wiley.

  \bibitem{4a} N. Fanizzi. {\em Corso di Apprendimento Automatico}, 2009: Laurea Magistrale in Informatica, Uniba.
  
  \bibitem{5a} H. Arsham. {\em Forecasting by Smoothing Techniques}, 2015.
  
  \bibitem{6a} M. Brett. {\em Corso di Apprendimento Automatico}, 2013 : MRC Cognition and Brain Sciences Unit.
  
    \bibitem{7a} R.J. Hyndman, G. Athanasopoulos. {\em Forecasting: principles and practice}, 2013.
    
    \bibitem{8a} G. Righini. {\em Corso di Logistica}, 2013: Laurea Magistrale in Informatica, Unimi.
    \bibitem{9a} C.A. Sims. {\em Macroeconomics and Reality}, 1980.
    
    \bibitem{10a} J.D. Hamilton. {\em Time Series Analysis}, 1994: Princeton University Press.
   
    \bibitem{11a} D. Buono. {\em Analisi econometrica dinamica del settore Agricoltura}, 2007: Tesi di dottorato in Scienze Economiche, Unina.
    
    \bibitem{12a} {\em https://www.r-project.org/about.html}.
    
    \bibitem{13a} V. Fanelli. {\em Uso di modelli VAR nella previsione di modelli di regressione in una rete di sensori multi-variati}, 2015: Tesi di laurea in Metodi Avanzati di Programmazione, Uniba.
    
     \bibitem{14a} {\em https://it.wikipedia.org/wiki/Outlier}.
     
     \bibitem{15a} M. Ross Sheldon. {\em Introduzione alla statistica}, 2014, Maggioli Editore.
      
    
  \end{thebibliography}
\chapter{Ringraziamenti}



\end{document}